{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rithw\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55555556, 0.29166667, 0.67857143, 0.70833333],\n",
       "       [0.25      , 0.58333333, 0.05357143, 0.04166667],\n",
       "       [0.52777778, 0.375     , 0.57142857, 0.5       ],\n",
       "       [0.94444444, 0.33333333, 1.        , 0.79166667],\n",
       "       [0.02777778, 0.41666667, 0.03571429, 0.04166667],\n",
       "       [0.19444444, 0.5       , 0.01785714, 0.04166667],\n",
       "       [0.94444444, 0.41666667, 0.89285714, 0.91666667],\n",
       "       [0.5       , 0.375     , 0.64285714, 0.54166667],\n",
       "       [0.22222222, 0.625     , 0.05357143, 0.08333333],\n",
       "       [0.36111111, 0.41666667, 0.60714286, 0.58333333],\n",
       "       [0.16666667, 0.66666667, 0.05357143, 0.        ],\n",
       "       [0.44444444, 0.5       , 0.66071429, 0.70833333],\n",
       "       [0.22222222, 0.54166667, 0.10714286, 0.16666667],\n",
       "       [0.75      , 0.5       , 0.64285714, 0.54166667],\n",
       "       [0.80555556, 0.66666667, 0.89285714, 1.        ],\n",
       "       [0.36111111, 0.29166667, 0.55357143, 0.5       ],\n",
       "       [0.25      , 0.875     , 0.07142857, 0.        ],\n",
       "       [0.55555556, 0.54166667, 0.64285714, 0.625     ],\n",
       "       [0.47222222, 0.08333333, 0.51785714, 0.375     ],\n",
       "       [0.58333333, 0.375     , 0.57142857, 0.5       ],\n",
       "       [0.33333333, 0.25      , 0.58928571, 0.45833333],\n",
       "       [0.69444444, 0.33333333, 0.66071429, 0.54166667],\n",
       "       [0.41666667, 0.83333333, 0.01785714, 0.04166667],\n",
       "       [0.69444444, 0.5       , 0.85714286, 0.91666667],\n",
       "       [0.22222222, 0.75      , 0.08928571, 0.04166667],\n",
       "       [0.05555556, 0.125     , 0.03571429, 0.08333333],\n",
       "       [0.22222222, 0.625     , 0.05357143, 0.04166667],\n",
       "       [0.33333333, 0.20833333, 0.51785714, 0.5       ],\n",
       "       [0.52777778, 0.33333333, 0.66071429, 0.70833333],\n",
       "       [0.44444444, 0.41666667, 0.71428571, 0.70833333],\n",
       "       [0.38888889, 0.33333333, 0.60714286, 0.5       ],\n",
       "       [0.19444444, 0.58333333, 0.08928571, 0.125     ],\n",
       "       [0.58333333, 0.5       , 0.75      , 0.91666667],\n",
       "       [0.16666667, 0.20833333, 0.60714286, 0.66666667],\n",
       "       [0.55555556, 0.20833333, 0.69642857, 0.75      ],\n",
       "       [0.22222222, 0.75      , 0.14285714, 0.125     ],\n",
       "       [0.91666667, 0.41666667, 0.98214286, 0.83333333],\n",
       "       [0.72222222, 0.45833333, 0.76785714, 0.83333333],\n",
       "       [0.58333333, 0.33333333, 0.80357143, 0.875     ],\n",
       "       [0.13888889, 0.41666667, 0.05357143, 0.        ],\n",
       "       [0.22222222, 0.75      , 0.07142857, 0.08333333],\n",
       "       [0.66666667, 0.45833333, 0.58928571, 0.54166667],\n",
       "       [0.58333333, 0.33333333, 0.80357143, 0.83333333],\n",
       "       [0.41666667, 0.25      , 0.51785714, 0.45833333],\n",
       "       [0.5       , 0.33333333, 0.64285714, 0.45833333],\n",
       "       [0.19444444, 0.54166667, 0.05357143, 0.04166667],\n",
       "       [0.16666667, 0.16666667, 0.39285714, 0.375     ],\n",
       "       [0.55555556, 0.58333333, 0.80357143, 0.95833333],\n",
       "       [0.30555556, 0.41666667, 0.60714286, 0.58333333],\n",
       "       [0.41666667, 0.29166667, 0.5       , 0.45833333],\n",
       "       [0.19444444, 0.625     , 0.08928571, 0.20833333],\n",
       "       [0.33333333, 0.91666667, 0.05357143, 0.04166667],\n",
       "       [0.36111111, 0.375     , 0.44642857, 0.5       ],\n",
       "       [0.38888889, 0.20833333, 0.69642857, 0.79166667],\n",
       "       [0.5       , 0.41666667, 0.625     , 0.54166667],\n",
       "       [0.19444444, 0.        , 0.42857143, 0.375     ],\n",
       "       [0.66666667, 0.54166667, 0.82142857, 0.83333333],\n",
       "       [0.        , 0.41666667, 0.        , 0.        ],\n",
       "       [0.47222222, 0.375     , 0.60714286, 0.58333333],\n",
       "       [0.36111111, 0.20833333, 0.5       , 0.41666667],\n",
       "       [0.66666667, 0.20833333, 0.83928571, 0.70833333],\n",
       "       [0.11111111, 0.5       , 0.08928571, 0.04166667],\n",
       "       [0.33333333, 0.125     , 0.51785714, 0.5       ],\n",
       "       [0.30555556, 0.70833333, 0.07142857, 0.04166667],\n",
       "       [0.13888889, 0.58333333, 0.08928571, 0.04166667],\n",
       "       [0.33333333, 0.16666667, 0.46428571, 0.375     ],\n",
       "       [0.22222222, 0.58333333, 0.07142857, 0.04166667],\n",
       "       [1.        , 0.75      , 0.94642857, 0.79166667],\n",
       "       [0.5       , 0.25      , 0.80357143, 0.54166667],\n",
       "       [0.08333333, 0.45833333, 0.07142857, 0.04166667],\n",
       "       [0.52777778, 0.58333333, 0.76785714, 0.91666667],\n",
       "       [0.44444444, 0.41666667, 0.55357143, 0.58333333],\n",
       "       [0.30555556, 0.79166667, 0.03571429, 0.125     ],\n",
       "       [0.16666667, 0.45833333, 0.07142857, 0.04166667],\n",
       "       [0.19444444, 0.58333333, 0.07142857, 0.04166667],\n",
       "       [0.61111111, 0.41666667, 0.78571429, 0.70833333],\n",
       "       [0.38888889, 1.        , 0.07142857, 0.125     ],\n",
       "       [0.72222222, 0.45833333, 0.67857143, 0.58333333],\n",
       "       [0.61111111, 0.5       , 0.71428571, 0.79166667],\n",
       "       [0.16666667, 0.45833333, 0.07142857, 0.        ],\n",
       "       [0.38888889, 0.33333333, 0.53571429, 0.5       ],\n",
       "       [0.19444444, 0.66666667, 0.05357143, 0.04166667],\n",
       "       [0.63888889, 0.375     , 0.625     , 0.5       ],\n",
       "       [0.55555556, 0.33333333, 0.71428571, 0.58333333],\n",
       "       [0.47222222, 0.08333333, 0.69642857, 0.58333333],\n",
       "       [0.47222222, 0.58333333, 0.60714286, 0.625     ],\n",
       "       [0.25      , 0.625     , 0.07142857, 0.04166667],\n",
       "       [0.55555556, 0.125     , 0.58928571, 0.5       ],\n",
       "       [0.38888889, 0.41666667, 0.55357143, 0.45833333],\n",
       "       [0.61111111, 0.41666667, 0.73214286, 0.79166667],\n",
       "       [0.30555556, 0.58333333, 0.10714286, 0.04166667],\n",
       "       [0.58333333, 0.29166667, 0.75      , 0.75      ],\n",
       "       [0.58333333, 0.5       , 0.60714286, 0.58333333],\n",
       "       [0.38888889, 0.25      , 0.42857143, 0.375     ],\n",
       "       [0.63888889, 0.41666667, 0.58928571, 0.54166667],\n",
       "       [0.66666667, 0.41666667, 0.73214286, 0.91666667],\n",
       "       [0.30555556, 0.79166667, 0.10714286, 0.125     ],\n",
       "       [0.83333333, 0.375     , 0.92857143, 0.70833333],\n",
       "       [0.02777778, 0.375     , 0.05357143, 0.04166667],\n",
       "       [0.41666667, 0.29166667, 0.71428571, 0.75      ],\n",
       "       [0.27777778, 0.70833333, 0.07142857, 0.04166667],\n",
       "       [0.72222222, 0.45833333, 0.71428571, 0.91666667],\n",
       "       [0.86111111, 0.33333333, 0.89285714, 0.75      ],\n",
       "       [0.66666667, 0.45833333, 0.80357143, 0.95833333],\n",
       "       [0.41666667, 0.29166667, 0.53571429, 0.375     ],\n",
       "       [0.08333333, 0.5       , 0.05357143, 0.04166667],\n",
       "       [0.94444444, 0.75      , 1.        , 0.875     ],\n",
       "       [0.19444444, 0.625     , 0.03571429, 0.08333333],\n",
       "       [0.58333333, 0.45833333, 0.78571429, 0.70833333],\n",
       "       [0.16666667, 0.41666667, 0.05357143, 0.04166667],\n",
       "       [0.41666667, 0.33333333, 0.71428571, 0.95833333],\n",
       "       [0.30555556, 0.58333333, 0.07142857, 0.125     ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(8, input_dim = 4, activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 235\n",
      "Trainable params: 235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " - 0s - loss: 1.1633 - accuracy: 0.0179\n",
      "Epoch 2/150\n",
      " - 0s - loss: 1.1526 - accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      " - 0s - loss: 1.1424 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      " - 0s - loss: 1.1321 - accuracy: 0.2411\n",
      "Epoch 5/150\n",
      " - 0s - loss: 1.1225 - accuracy: 0.3214\n",
      "Epoch 6/150\n",
      " - 0s - loss: 1.1128 - accuracy: 0.3214\n",
      "Epoch 7/150\n",
      " - 0s - loss: 1.1038 - accuracy: 0.3214\n",
      "Epoch 8/150\n",
      " - 0s - loss: 1.0949 - accuracy: 0.3304\n",
      "Epoch 9/150\n",
      " - 0s - loss: 1.0857 - accuracy: 0.3393\n",
      "Epoch 10/150\n",
      " - 0s - loss: 1.0764 - accuracy: 0.3661\n",
      "Epoch 11/150\n",
      " - 0s - loss: 1.0667 - accuracy: 0.3750\n",
      "Epoch 12/150\n",
      " - 0s - loss: 1.0564 - accuracy: 0.3839\n",
      "Epoch 13/150\n",
      " - 0s - loss: 1.0463 - accuracy: 0.4107\n",
      "Epoch 14/150\n",
      " - 0s - loss: 1.0358 - accuracy: 0.5089\n",
      "Epoch 15/150\n",
      " - 0s - loss: 1.0251 - accuracy: 0.5536\n",
      "Epoch 16/150\n",
      " - 0s - loss: 1.0140 - accuracy: 0.6429\n",
      "Epoch 17/150\n",
      " - 0s - loss: 1.0028 - accuracy: 0.7054\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.9908 - accuracy: 0.7411\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.9784 - accuracy: 0.7500\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.9658 - accuracy: 0.7321\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.9534 - accuracy: 0.7143\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.9404 - accuracy: 0.6964\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.9280 - accuracy: 0.6786\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.9151 - accuracy: 0.6696\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.9022 - accuracy: 0.6696\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.8896 - accuracy: 0.6696\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.8771 - accuracy: 0.6696\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.8644 - accuracy: 0.6696\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.8524 - accuracy: 0.6696\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.8394 - accuracy: 0.6696\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.8271 - accuracy: 0.6696\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.8138 - accuracy: 0.6696\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.8013 - accuracy: 0.6696\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.7883 - accuracy: 0.6696\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.7753 - accuracy: 0.6696\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.7625 - accuracy: 0.6696\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.7496 - accuracy: 0.6696\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.7375 - accuracy: 0.6696\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.7248 - accuracy: 0.6696\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.7131 - accuracy: 0.6696\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.7013 - accuracy: 0.6696\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.6896 - accuracy: 0.6696\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.6784 - accuracy: 0.6696\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.6678 - accuracy: 0.6696\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.6571 - accuracy: 0.6696\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.6470 - accuracy: 0.6696\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.6376 - accuracy: 0.6696\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.6274 - accuracy: 0.6696\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.6184 - accuracy: 0.6696\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.6100 - accuracy: 0.6696\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.6013 - accuracy: 0.6696\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.5932 - accuracy: 0.6696\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.5852 - accuracy: 0.6696\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.5776 - accuracy: 0.6696\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.5704 - accuracy: 0.6696\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.5624 - accuracy: 0.6696\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.5548 - accuracy: 0.6696\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.5476 - accuracy: 0.6696\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.5396 - accuracy: 0.6696\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.5325 - accuracy: 0.6696\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.5260 - accuracy: 0.6696\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.5195 - accuracy: 0.6696\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.5136 - accuracy: 0.6696\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.5078 - accuracy: 0.6696\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.5029 - accuracy: 0.6696\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.4982 - accuracy: 0.6696\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.4936 - accuracy: 0.6696\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.4891 - accuracy: 0.6696\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.4849 - accuracy: 0.6696\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.4809 - accuracy: 0.6696\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.4770 - accuracy: 0.6696\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.4733 - accuracy: 0.6875\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.4698 - accuracy: 0.6875\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.4668 - accuracy: 0.6964\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.4633 - accuracy: 0.7054\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.4602 - accuracy: 0.7054\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.4570 - accuracy: 0.7054\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.4542 - accuracy: 0.7143\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.4512 - accuracy: 0.7321\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.4483 - accuracy: 0.7679\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.4459 - accuracy: 0.7857\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.4430 - accuracy: 0.7946\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.4403 - accuracy: 0.7946\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.4376 - accuracy: 0.7946\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.4355 - accuracy: 0.7857\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.4326 - accuracy: 0.7857\n",
      "Epoch 87/150\n",
      " - 0s - loss: 0.4302 - accuracy: 0.7857\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.4276 - accuracy: 0.7946\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.4251 - accuracy: 0.8036\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.4229 - accuracy: 0.8214\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.4206 - accuracy: 0.8482\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.4184 - accuracy: 0.8571\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.4160 - accuracy: 0.8661\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.4136 - accuracy: 0.8571\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.4112 - accuracy: 0.8571\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.4086 - accuracy: 0.8482\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.4062 - accuracy: 0.8393\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.4041 - accuracy: 0.8304\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.4015 - accuracy: 0.8304\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.3989 - accuracy: 0.8571\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.3962 - accuracy: 0.8750\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.3939 - accuracy: 0.8750\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.3914 - accuracy: 0.8750\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.3890 - accuracy: 0.9018\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.3866 - accuracy: 0.9018\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.3845 - accuracy: 0.9107\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.3815 - accuracy: 0.9196\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.3787 - accuracy: 0.9196\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.3762 - accuracy: 0.9286\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.3738 - accuracy: 0.9286\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.3709 - accuracy: 0.9375\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.3685 - accuracy: 0.9196\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.3657 - accuracy: 0.9107\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.3634 - accuracy: 0.9107\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.3610 - accuracy: 0.9107\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.3583 - accuracy: 0.9107\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.3558 - accuracy: 0.9286\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.3530 - accuracy: 0.9375\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.3499 - accuracy: 0.9375\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.3472 - accuracy: 0.9375\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.3445 - accuracy: 0.9375\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.3417 - accuracy: 0.9375\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.3390 - accuracy: 0.9375\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.3363 - accuracy: 0.9375\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.3332 - accuracy: 0.9375\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.3304 - accuracy: 0.9375\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.3277 - accuracy: 0.9375\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.3245 - accuracy: 0.9375\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.3209 - accuracy: 0.9375\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.3177 - accuracy: 0.9554\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.3149 - accuracy: 0.9643\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.3119 - accuracy: 0.9643\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.3086 - accuracy: 0.9643\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.3052 - accuracy: 0.9643\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.3021 - accuracy: 0.9643\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.2992 - accuracy: 0.9643\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.2966 - accuracy: 0.9643\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.2929 - accuracy: 0.9643\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.2899 - accuracy: 0.9643\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.2868 - accuracy: 0.9643\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.2838 - accuracy: 0.9643\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.2804 - accuracy: 0.9643\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.2773 - accuracy: 0.9643\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.2749 - accuracy: 0.9554\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.2724 - accuracy: 0.9554\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.2702 - accuracy: 0.9643\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.2666 - accuracy: 0.9643\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.2635 - accuracy: 0.9554\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.2602 - accuracy: 0.9643\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.2567 - accuracy: 0.9643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c3fa8ad208>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs=150, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = to_categorical(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.89      0.62      0.73        13\n",
      "           2       0.72      0.93      0.81        14\n",
      "\n",
      "   micro avg       0.84      0.84      0.84        38\n",
      "   macro avg       0.87      0.85      0.85        38\n",
      "weighted avg       0.86      0.84      0.84        38\n",
      " samples avg       0.84      0.84      0.84        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8421052631578947\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.argmax(axis=1)\n",
    "y_test = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0  8  5]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = load_model(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 235\n",
      "Trainable params: 235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
